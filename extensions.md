Extensions
==========

## Positional Penalty:

   For this extension, we introduced a penalty based on the relative positions of the Spanish sentence and the English sentence in the raw data. This effectively penalized translation sentences that are very far apart. We noticed that this did not have much of an effect on the FScore and in fact severely hurt our model. Only by weighting this penalty to be a very small fraction, do we see an improvement in the overall score. This is due to the fact that the English and Spanish raw data are not ordered in the same way. We noticed that the sections do not match up and that to find an optimal translation, we usually ahve to look for a sentence that is in a far away position. This thought is supported by setting the window size to 200.

## One-to-One Constraint:

   The default and baseline implementations do not enforce a one-to-one matching between sentences. In this extension we only allow one English sentence to match with one Spanish sentence. We avoid greedy matching by allowing for a slightly increased window size of 200 sentences. This makes sure that a sentence is not automatically matched just because it is seen first, instead it still chooses the best sentence in the window and eliminates it from being matched with future sentences. By enforcing a one-to-one matching scheme, significant improvements were made in our score. This constraint improved the score from 0.365 (generated by the baseline) to 0.425. I believe the increase in score came from eliminating the large number of duplicate matches in Spanish sentences. Our previous algorithm, searches through all Spanish sentences in the window for the best match according to our baseline algorithm, this resulted in similar sentences matching the same sentence and producing redundancy in the answer key. With this redundancy removed, sentences that include lots of similar proper nouns that matched with many sentences were restricted to one match, reducing the errors in the generated alignment.

## Sentence Length Ratio:

   We assume that short sentences in a source language translate as short sentences in a target language, and long sentences in a source language translate as long sentences in a target language. More specifically, given a huge corpus of translations, the length of sentences in a source language and the length of their translations in a target language should converge to a constant ratio, **r***. If the langauges are of equal verbosity, **r*** should be 1:1. If the source langauge is more verbose than the target language, we expect **r*** > 1, and we expect **r*** < 1 if the source language is more concise than the target language.

   Under this assumption, two sentences are likely to be parallel if the ratio of their lengths, r(source, translation), is close to **r***. I implemented an extension that takes a ratio **r*** as a parameter. For each source sentence, it looks at each candidate translation and computs r(source, candidate). Scores for candidates (as generated by the baseline function) are penalized in proportion to the distance between their r(source, candidate) and **r***.

This extension proved to be extremely effective at improving both precision and recall above the baseline. Without changing any other parameters, assuming an **r*** of 1.18 for Spanish:English improves FScore by 30.0%.

## Gradient Ascent:

The gradient ascent algorithm attempts to maximize the FScore as a function of the paramters used to generate better sentence pairs. Since the analytic form of FScore as a function of the parameters is unknown, a Monte Carlo method is used where the gradient is calculated by locally sampling around a mean parameter vector with some discrete resolution in each direction. Some parameters have additional constraints. For instance the gradient ascnet for the baseline code has a window-size parameter that must be a positive integer because it is used for array indexing.

It is assumed that each parameter is linearly independent of one another, though this is a provably false assumption given by the presence of local maxima. Additional parameters can be used to smooth and improve the FScore function or even achieve full convexity if appropriate features are chosen. On the baseline code, the gradient ascent finds a local maximum of parameters 0.3748, a slight improvement from the baseline score of 0.365.

## Rewarding Rare Proper Nouns:

Our baseline implemented a feature that counted the number of proper nouns that are the same in the English and Spanish sentences. One problem with this approach is that some articles might have the same proper noun in many places through the text, and this would not necessarily be a good indicator of alignment. For example, an article about the Beatles would have the proper nouns John and Lennon in multiple sentences and this could cause false positive alignments. To solve this problem, we corrected for the number of times the proper noun appeared in the corpus. We implemented this by adding the inverse of the total number of times a matched proper noun was found in the corpus to the total number of proper noun matches for that sentence for each match, instead of just adding 1. This correction resulted in improved scores of precision = 0.332589, recall = 0.464174, and total score = 0.387516. This was an improvement on the baseline total score of 0.365.